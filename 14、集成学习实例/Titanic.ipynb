{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "题目：\n",
    "\n",
    "kaggle上的一道练习题，将所给的数据先进行预处理，再通过机器学习模型完成对数据集的学习和拟合，是分类精确度最高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大致分为：数据预处理和模型拟合两部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义载入数据函数（包括预处理在内）\n",
    "def load_data(file_name, is_train):\n",
    "    data = pd.read_csv(file_name)  # 数据文件路径\n",
    "    print ('data.describe() = \\n',data.describe()) # 打印各个数据的描述（均值、平均数、方差、中位数等）\n",
    "\n",
    "    # 性别\n",
    "    data['Sex'] = data['Sex'].map({'female': 0, 'male': 1}).astype(int) # 男性映射为1，女性为0\n",
    "\n",
    "    # 补齐船票价格缺失值\n",
    "    if len(data.Fare[data.Fare == 0]) > 0:  # 将船票价格为0的拿出来\n",
    "        fare = np.zeros(3)\n",
    "        for f in range(0, 3):               # 分别算出1、2、3等仓的中位数\n",
    "            fare[f] = data[data.Pclass == f + 1]['Fare'].dropna().median()\n",
    "        for f in range(0, 3):               # 将空缺船票的位置用该仓的中位数代替\n",
    "            data.loc[(data.Fare.isnull()) & (data.Pclass == f + 1), 'Fare'] = fare[f]\n",
    "\n",
    "    # 年龄：使用均值代替缺失值（比较垃圾）\n",
    "    # mean_age = data['Age'].dropna().mean()\n",
    "    # data.loc[(data.Age.isnull()), 'Age'] = mean_age\n",
    "    \n",
    "    # 年龄：使用随机森林预测年龄缺失值\n",
    "    if is_train:\n",
    "        \n",
    "        # 年龄预测的预处理工作\n",
    "        print ('随机森林预测缺失年龄：--start--')\n",
    "        data_for_age = data[['Age', 'Survived', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]   # 年龄不缺失的数据（训练集）\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]     # 年龄为空的部分（测试集）\n",
    "        # print (age_exist)\n",
    "        x = age_exist.values[:, 1:]     # 除了年龄那一列的作为x\n",
    "        y = age_exist.values[:, 0]      # 年龄作为y（需要预测）\n",
    "        \n",
    "        # 用随机森林做预测\n",
    "        rfr = RandomForestRegressor(n_estimators=100)  \n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        # print (age_hat)\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat  # 只要age为空就进行补充\n",
    "        print ('随机森林预测缺失年龄：--over--')\n",
    "    else:\n",
    "        # 对于测试数据中没有'Survived'这一列的处理方法（和之前的方法是一样的）\n",
    "        print ('随机森林预测缺失年龄2：--start--')\n",
    "        data_for_age = data[['Age', 'Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "        age_exist = data_for_age.loc[(data.Age.notnull())]  # 年龄不缺失的数据\n",
    "        age_null = data_for_age.loc[(data.Age.isnull())]\n",
    "        # print (age_exist)\n",
    "        x = age_exist.values[:, 1:]\n",
    "        y = age_exist.values[:, 0]\n",
    "        rfr = RandomForestRegressor(n_estimators=1000)\n",
    "        rfr.fit(x, y)\n",
    "        age_hat = rfr.predict(age_null.values[:, 1:])\n",
    "        # print (age_hat)\n",
    "        data.loc[(data.Age.isnull()), 'Age'] = age_hat   # 只要age为空就进行补充\n",
    "        print ('随机森林预测缺失年龄2：--over--')\n",
    "\n",
    "    # 起始城市（保存为4列，类似 one-hot 编码）\n",
    "    data.loc[(data.Embarked.isnull()), 'Embarked'] = 'S'  # 保留缺失出发城市\n",
    "    # data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2, 'U': 0}).astype(int)\n",
    "    # print (data['Embarked'])\n",
    "    embarked_data = pd.get_dummies(data.Embarked)\n",
    "    # print (embarked_data)\n",
    "    # embarked_data = embarked_data.rename(columns={'S': 'Southampton', 'C': 'Cherbourg', 'Q': 'Queenstown', 'U': 'UnknownCity'})\n",
    "    embarked_data = embarked_data.rename(columns=lambda x: 'Embarked_' + str(x))\n",
    "    data = pd.concat([data, embarked_data], axis=1)\n",
    "    print (data.describe())\n",
    "    \n",
    "    # 保存为一个新的文件 'New_Data.csv' 这是一个经过处理之后的文件\n",
    "    data.to_csv('New_Data.csv')\n",
    "    x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']]\n",
    "    # x = data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "    y = None\n",
    "    if 'Survived' in data:\n",
    "        y = data['Survived']\n",
    "\n",
    "    # 将数据转换为numpy的格式，方便操作\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # 将 x 、 y拷贝5份作为训练数据，增加精确率\n",
    "    x = np.tile(x, (5, 1))\n",
    "    y = np.tile(y, (5, ))\n",
    "    if is_train:\n",
    "        return x, y\n",
    "    return x, data['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、使用模型学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义得分函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(a, b, tip):\n",
    "    acc = a.ravel() == b.ravel()\n",
    "    acc_rate = 100 * float(acc.sum()) / a.size\n",
    "    # print ('%s正确率：%.3f%%' % (tip, acc_rate))\n",
    "    return acc_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义记录结果函数（这里没有用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_result(c, c_type):\n",
    "    file_name = '12.Titanic.test.csv'\n",
    "    x, passenger_id = load_data(file_name, False)\n",
    "\n",
    "    if type == 3:\n",
    "        x = xgb.DMatrix(x)\n",
    "    y = c.predict(x)\n",
    "    y[y > 0.5] = 1\n",
    "    y[~(y > 0.5)] = 0\n",
    "\n",
    "    predictions_file = open(\"Prediction_%d.csv\" % c_type, \"wb\")\n",
    "    open_file_object = csv.writer(predictions_file)\n",
    "    open_file_object.writerow([\"PassengerId\", \"Survived\"])\n",
    "    open_file_object.writerows(zip(passenger_id, y))\n",
    "    predictions_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.describe() = \n",
      "        PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "随机森林预测缺失年龄：--start--\n",
      "随机森林预测缺失年龄：--over--\n",
      "       PassengerId    Survived      Pclass         Sex         Age  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642    0.647587   29.693862   \n",
      "std     257.353842    0.486592    0.836071    0.477990   13.743586   \n",
      "min       1.000000    0.000000    1.000000    0.000000    0.420000   \n",
      "25%     223.500000    0.000000    2.000000    0.000000   21.000000   \n",
      "50%     446.000000    0.000000    3.000000    1.000000   28.000000   \n",
      "75%     668.500000    1.000000    3.000000    1.000000   37.000000   \n",
      "max     891.000000    1.000000    3.000000    1.000000   80.000000   \n",
      "\n",
      "            SibSp       Parch        Fare  Embarked_C  Embarked_Q  Embarked_S  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean     0.523008    0.381594   32.204208    0.188552    0.086420    0.722783   \n",
      "std      1.102743    0.806057   49.693429    0.391372    0.281141    0.447876   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    7.910400    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000   14.454200    0.000000    0.000000    1.000000   \n",
      "75%      1.000000    0.000000   31.000000    0.000000    0.000000    1.000000   \n",
      "max      8.000000    6.000000  512.329200    1.000000    1.000000    1.000000   \n",
      "\n",
      "       Embarked_U  \n",
      "count  891.000000  \n",
      "mean     0.002245  \n",
      "std      0.047351  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      0.000000  \n",
      "max      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# 读入数据\n",
    "x, y = load_data('12.Titanic.train.csv', True)\n",
    "# 分割数据集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Logistic回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic回归：79.129%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 创建模型，使用 l2 正则项\n",
    "lr = LogisticRegression(penalty='l2') \n",
    "# 拟合模型\n",
    "lr.fit(x_train, y_train)\n",
    "# 预测数据\n",
    "y_hat = lr.predict(x_test)\n",
    "# 模型得分\n",
    "lr_rate = show_accuracy(y_hat, y_test, 'Logistic回归 ')\n",
    "# write_result(lr, 1)\n",
    "print ('Logistic回归：%.3f%%' % lr_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林：97.397%\n"
     ]
    }
   ],
   "source": [
    "# 构造随机森林（20颗树）\n",
    "rfc = RandomForestClassifier(n_estimators=20)\n",
    "# 拟合模型\n",
    "rfc.fit(x_train, y_train)\n",
    "# 预测数据\n",
    "y_hat = rfc.predict(x_test)\n",
    "# 模型得分\n",
    "rfc_rate = show_accuracy(y_hat, y_test, '随机森林 ')\n",
    "# write_result(rfc, 2)\n",
    "print ('随机森林：%.3f%%' % rfc_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-error:0.194345\ttrain-error:0.15806\n",
      "[1]\teval-error:0.194345\ttrain-error:0.15806\n",
      "[2]\teval-error:0.194345\ttrain-error:0.15806\n",
      "[3]\teval-error:0.194345\ttrain-error:0.15806\n",
      "[4]\teval-error:0.194345\ttrain-error:0.15806\n",
      "[5]\teval-error:0.192549\ttrain-error:0.157611\n",
      "[6]\teval-error:0.192549\ttrain-error:0.157611\n",
      "[7]\teval-error:0.185817\ttrain-error:0.153121\n",
      "[8]\teval-error:0.185817\ttrain-error:0.153121\n",
      "[9]\teval-error:0.185817\ttrain-error:0.153121\n",
      "[10]\teval-error:0.185817\ttrain-error:0.153121\n",
      "[11]\teval-error:0.185817\ttrain-error:0.153121\n",
      "[12]\teval-error:0.185817\ttrain-error:0.153121\n",
      "[13]\teval-error:0.185817\ttrain-error:0.153121\n",
      "[14]\teval-error:0.185817\ttrain-error:0.153121\n",
      "[15]\teval-error:0.185817\ttrain-error:0.153121\n",
      "[16]\teval-error:0.175494\ttrain-error:0.152223\n",
      "[17]\teval-error:0.175494\ttrain-error:0.152223\n",
      "[18]\teval-error:0.175494\ttrain-error:0.152223\n",
      "[19]\teval-error:0.175494\ttrain-error:0.152223\n",
      "[20]\teval-error:0.175494\ttrain-error:0.152223\n",
      "[21]\teval-error:0.175045\ttrain-error:0.150427\n",
      "[22]\teval-error:0.171903\ttrain-error:0.146834\n",
      "[23]\teval-error:0.171903\ttrain-error:0.146834\n",
      "[24]\teval-error:0.171454\ttrain-error:0.145038\n",
      "[25]\teval-error:0.171454\ttrain-error:0.145038\n",
      "[26]\teval-error:0.165171\ttrain-error:0.135608\n",
      "[27]\teval-error:0.170108\ttrain-error:0.13965\n",
      "[28]\teval-error:0.170557\ttrain-error:0.141446\n",
      "[29]\teval-error:0.170108\ttrain-error:0.13965\n",
      "[30]\teval-error:0.171903\ttrain-error:0.137854\n",
      "[31]\teval-error:0.170108\ttrain-error:0.137405\n",
      "[32]\teval-error:0.169659\ttrain-error:0.135608\n",
      "[33]\teval-error:0.169659\ttrain-error:0.135608\n",
      "[34]\teval-error:0.169659\ttrain-error:0.135608\n",
      "[35]\teval-error:0.169659\ttrain-error:0.135608\n",
      "[36]\teval-error:0.169659\ttrain-error:0.135608\n",
      "[37]\teval-error:0.169659\ttrain-error:0.135608\n",
      "[38]\teval-error:0.166966\ttrain-error:0.133812\n",
      "[39]\teval-error:0.171005\ttrain-error:0.136507\n",
      "[40]\teval-error:0.171005\ttrain-error:0.136507\n",
      "[41]\teval-error:0.16921\ttrain-error:0.133812\n",
      "[42]\teval-error:0.166517\ttrain-error:0.134261\n",
      "[43]\teval-error:0.166517\ttrain-error:0.134261\n",
      "[44]\teval-error:0.168312\ttrain-error:0.13471\n",
      "[45]\teval-error:0.170557\ttrain-error:0.13471\n",
      "[46]\teval-error:0.165619\ttrain-error:0.132914\n",
      "[47]\teval-error:0.164273\ttrain-error:0.132016\n",
      "[48]\teval-error:0.159336\ttrain-error:0.13022\n",
      "[49]\teval-error:0.159336\ttrain-error:0.13022\n",
      "[50]\teval-error:0.159336\ttrain-error:0.13022\n",
      "[51]\teval-error:0.162478\ttrain-error:0.131567\n",
      "[52]\teval-error:0.16158\ttrain-error:0.13022\n",
      "[53]\teval-error:0.158438\ttrain-error:0.128873\n",
      "[54]\teval-error:0.157092\ttrain-error:0.127975\n",
      "[55]\teval-error:0.158438\ttrain-error:0.128873\n",
      "[56]\teval-error:0.15754\ttrain-error:0.127526\n",
      "[57]\teval-error:0.15395\ttrain-error:0.122137\n",
      "[58]\teval-error:0.156194\ttrain-error:0.124383\n",
      "[59]\teval-error:0.156194\ttrain-error:0.124383\n",
      "[60]\teval-error:0.154399\ttrain-error:0.123934\n",
      "[61]\teval-error:0.153052\ttrain-error:0.123035\n",
      "[62]\teval-error:0.153052\ttrain-error:0.123035\n",
      "[63]\teval-error:0.15395\ttrain-error:0.124383\n",
      "[64]\teval-error:0.15395\ttrain-error:0.124383\n",
      "[65]\teval-error:0.153052\ttrain-error:0.123035\n",
      "[66]\teval-error:0.152154\ttrain-error:0.119443\n",
      "[67]\teval-error:0.151257\ttrain-error:0.118096\n",
      "[68]\teval-error:0.147666\ttrain-error:0.114953\n",
      "[69]\teval-error:0.147217\ttrain-error:0.113157\n",
      "[70]\teval-error:0.147217\ttrain-error:0.110912\n",
      "[71]\teval-error:0.147217\ttrain-error:0.110912\n",
      "[72]\teval-error:0.147217\ttrain-error:0.110912\n",
      "[73]\teval-error:0.147217\ttrain-error:0.110912\n",
      "[74]\teval-error:0.149461\ttrain-error:0.110912\n",
      "[75]\teval-error:0.149461\ttrain-error:0.110912\n",
      "[76]\teval-error:0.149013\ttrain-error:0.111361\n",
      "[77]\teval-error:0.149013\ttrain-error:0.111361\n",
      "[78]\teval-error:0.149013\ttrain-error:0.111361\n",
      "[79]\teval-error:0.149013\ttrain-error:0.111361\n",
      "[80]\teval-error:0.148564\ttrain-error:0.11181\n",
      "[81]\teval-error:0.145422\ttrain-error:0.110463\n",
      "[82]\teval-error:0.145422\ttrain-error:0.110463\n",
      "[83]\teval-error:0.14632\ttrain-error:0.109564\n",
      "[84]\teval-error:0.14632\ttrain-error:0.109564\n",
      "[85]\teval-error:0.144524\ttrain-error:0.109115\n",
      "[86]\teval-error:0.145871\ttrain-error:0.107768\n",
      "[87]\teval-error:0.144973\ttrain-error:0.106421\n",
      "[88]\teval-error:0.144524\ttrain-error:0.104625\n",
      "[89]\teval-error:0.143178\ttrain-error:0.105972\n",
      "[90]\teval-error:0.136894\ttrain-error:0.101033\n",
      "[91]\teval-error:0.136894\ttrain-error:0.101033\n",
      "[92]\teval-error:0.136894\ttrain-error:0.101033\n",
      "[93]\teval-error:0.136894\ttrain-error:0.101033\n",
      "[94]\teval-error:0.138241\ttrain-error:0.101931\n",
      "[95]\teval-error:0.141831\ttrain-error:0.102829\n",
      "[96]\teval-error:0.141831\ttrain-error:0.102829\n",
      "[97]\teval-error:0.139587\ttrain-error:0.102829\n",
      "[98]\teval-error:0.143178\ttrain-error:0.105972\n",
      "[99]\teval-error:0.139587\ttrain-error:0.102829\n",
      "[100]\teval-error:0.143627\ttrain-error:0.105523\n",
      "[101]\teval-error:0.143627\ttrain-error:0.105523\n",
      "[102]\teval-error:0.144973\ttrain-error:0.106421\n",
      "[103]\teval-error:0.144973\ttrain-error:0.106421\n",
      "[104]\teval-error:0.144973\ttrain-error:0.106421\n",
      "[105]\teval-error:0.141831\ttrain-error:0.105074\n",
      "[106]\teval-error:0.141831\ttrain-error:0.105074\n",
      "[107]\teval-error:0.141831\ttrain-error:0.105074\n",
      "[108]\teval-error:0.141831\ttrain-error:0.105074\n",
      "[109]\teval-error:0.138241\ttrain-error:0.101931\n",
      "[110]\teval-error:0.138241\ttrain-error:0.101931\n",
      "[111]\teval-error:0.140036\ttrain-error:0.10238\n",
      "[112]\teval-error:0.135996\ttrain-error:0.097441\n",
      "[113]\teval-error:0.135996\ttrain-error:0.097441\n",
      "[114]\teval-error:0.134201\ttrain-error:0.096991\n",
      "[115]\teval-error:0.131957\ttrain-error:0.094746\n",
      "[116]\teval-error:0.133303\ttrain-error:0.095644\n",
      "[117]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[118]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[119]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[120]\teval-error:0.129713\ttrain-error:0.092501\n",
      "[121]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[122]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[123]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[124]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[125]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[126]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[127]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[128]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[129]\teval-error:0.131059\ttrain-error:0.093399\n",
      "[130]\teval-error:0.126122\ttrain-error:0.089358\n",
      "[131]\teval-error:0.124776\ttrain-error:0.08846\n",
      "[132]\teval-error:0.124776\ttrain-error:0.08846\n",
      "[133]\teval-error:0.126122\ttrain-error:0.089358\n",
      "[134]\teval-error:0.126122\ttrain-error:0.089358\n",
      "[135]\teval-error:0.126122\ttrain-error:0.089358\n",
      "[136]\teval-error:0.127469\ttrain-error:0.090256\n",
      "[137]\teval-error:0.125673\ttrain-error:0.087562\n",
      "[138]\teval-error:0.125673\ttrain-error:0.087562\n",
      "[139]\teval-error:0.125673\ttrain-error:0.087562\n",
      "[140]\teval-error:0.125673\ttrain-error:0.087562\n",
      "[141]\teval-error:0.125673\ttrain-error:0.087562\n",
      "[142]\teval-error:0.124776\ttrain-error:0.086215\n",
      "[143]\teval-error:0.124776\ttrain-error:0.086215\n",
      "[144]\teval-error:0.11939\ttrain-error:0.084868\n",
      "[145]\teval-error:0.118492\ttrain-error:0.08352\n",
      "[146]\teval-error:0.11939\ttrain-error:0.084868\n",
      "[147]\teval-error:0.118043\ttrain-error:0.081724\n",
      "[148]\teval-error:0.114452\ttrain-error:0.078581\n",
      "[149]\teval-error:0.113106\ttrain-error:0.079928\n",
      "[150]\teval-error:0.110862\ttrain-error:0.079928\n",
      "[151]\teval-error:0.110862\ttrain-error:0.079928\n",
      "[152]\teval-error:0.110862\ttrain-error:0.079928\n",
      "[153]\teval-error:0.110862\ttrain-error:0.079928\n",
      "[154]\teval-error:0.110862\ttrain-error:0.079928\n",
      "[155]\teval-error:0.110862\ttrain-error:0.079928\n",
      "[156]\teval-error:0.110413\ttrain-error:0.078132\n",
      "[157]\teval-error:0.110413\ttrain-error:0.078132\n",
      "[158]\teval-error:0.110413\ttrain-error:0.078132\n",
      "[159]\teval-error:0.110413\ttrain-error:0.078132\n",
      "[160]\teval-error:0.110413\ttrain-error:0.078132\n",
      "[161]\teval-error:0.110413\ttrain-error:0.078132\n",
      "[162]\teval-error:0.110413\ttrain-error:0.078132\n",
      "[163]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[164]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[165]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[166]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[167]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[168]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[169]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[170]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[171]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[172]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[173]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[174]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[175]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[176]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[177]\teval-error:0.112208\ttrain-error:0.078581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[179]\teval-error:0.114004\ttrain-error:0.07903\n",
      "[180]\teval-error:0.114004\ttrain-error:0.07903\n",
      "[181]\teval-error:0.112208\ttrain-error:0.078581\n",
      "[182]\teval-error:0.113106\ttrain-error:0.077683\n",
      "[183]\teval-error:0.114004\ttrain-error:0.07903\n",
      "[184]\teval-error:0.114004\ttrain-error:0.07903\n",
      "[185]\teval-error:0.110862\ttrain-error:0.077683\n",
      "[186]\teval-error:0.109066\ttrain-error:0.077234\n",
      "[187]\teval-error:0.106373\ttrain-error:0.075438\n",
      "[188]\teval-error:0.106373\ttrain-error:0.075438\n",
      "[189]\teval-error:0.106373\ttrain-error:0.075438\n",
      "[190]\teval-error:0.108169\ttrain-error:0.075887\n",
      "[191]\teval-error:0.107271\ttrain-error:0.07454\n",
      "[192]\teval-error:0.107271\ttrain-error:0.07454\n",
      "[193]\teval-error:0.107271\ttrain-error:0.07454\n",
      "[194]\teval-error:0.107271\ttrain-error:0.07454\n",
      "[195]\teval-error:0.107271\ttrain-error:0.07454\n",
      "[196]\teval-error:0.109066\ttrain-error:0.074989\n",
      "[197]\teval-error:0.107271\ttrain-error:0.07454\n",
      "[198]\teval-error:0.107271\ttrain-error:0.07454\n",
      "[199]\teval-error:0.107271\ttrain-error:0.07454\n",
      "[200]\teval-error:0.106822\ttrain-error:0.072744\n",
      "[201]\teval-error:0.106373\ttrain-error:0.073193\n",
      "[202]\teval-error:0.105476\ttrain-error:0.071846\n",
      "[203]\teval-error:0.105476\ttrain-error:0.071846\n",
      "[204]\teval-error:0.105027\ttrain-error:0.070049\n",
      "[205]\teval-error:0.105476\ttrain-error:0.071846\n",
      "[206]\teval-error:0.101885\ttrain-error:0.068702\n",
      "[207]\teval-error:0.101885\ttrain-error:0.068702\n",
      "[208]\teval-error:0.100539\ttrain-error:0.067804\n",
      "[209]\teval-error:0.100539\ttrain-error:0.067804\n",
      "[210]\teval-error:0.100539\ttrain-error:0.067804\n",
      "[211]\teval-error:0.100539\ttrain-error:0.067804\n",
      "[212]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[213]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[214]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[215]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[216]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[217]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[218]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[219]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[220]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[221]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[222]\teval-error:0.102334\ttrain-error:0.070498\n",
      "[223]\teval-error:0.100987\ttrain-error:0.0696\n",
      "[224]\teval-error:0.102334\ttrain-error:0.070498\n",
      "[225]\teval-error:0.102334\ttrain-error:0.070498\n",
      "[226]\teval-error:0.102334\ttrain-error:0.070498\n",
      "[227]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[228]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[229]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[230]\teval-error:0.101436\ttrain-error:0.069151\n",
      "[231]\teval-error:0.100539\ttrain-error:0.067804\n",
      "[232]\teval-error:0.100539\ttrain-error:0.067804\n",
      "[233]\teval-error:0.098743\ttrain-error:0.067355\n",
      "[234]\teval-error:0.098743\ttrain-error:0.067355\n",
      "[235]\teval-error:0.098294\ttrain-error:0.067804\n",
      "[236]\teval-error:0.098294\ttrain-error:0.067804\n",
      "[237]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[238]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[239]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[240]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[241]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[242]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[243]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[244]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[245]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[246]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[247]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[248]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[249]\teval-error:0.097397\ttrain-error:0.066457\n",
      "[250]\teval-error:0.096499\ttrain-error:0.06511\n",
      "[251]\teval-error:0.096499\ttrain-error:0.06511\n",
      "[252]\teval-error:0.095153\ttrain-error:0.064212\n",
      "[253]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[254]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[255]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[256]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[257]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[258]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[259]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[260]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[261]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[262]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[263]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[264]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[265]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[266]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[267]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[268]\teval-error:0.095153\ttrain-error:0.064212\n",
      "[269]\teval-error:0.092011\ttrain-error:0.062865\n",
      "[270]\teval-error:0.092011\ttrain-error:0.062865\n",
      "[271]\teval-error:0.091113\ttrain-error:0.061518\n",
      "[272]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[273]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[274]\teval-error:0.094255\ttrain-error:0.062865\n",
      "[275]\teval-error:0.093357\ttrain-error:0.061518\n",
      "[276]\teval-error:0.093357\ttrain-error:0.061518\n",
      "[277]\teval-error:0.093357\ttrain-error:0.061518\n",
      "[278]\teval-error:0.093357\ttrain-error:0.061518\n",
      "[279]\teval-error:0.090664\ttrain-error:0.059722\n",
      "[280]\teval-error:0.090664\ttrain-error:0.059722\n",
      "[281]\teval-error:0.087522\ttrain-error:0.058374\n",
      "[282]\teval-error:0.086625\ttrain-error:0.057027\n",
      "[283]\teval-error:0.084829\ttrain-error:0.056578\n",
      "[284]\teval-error:0.084829\ttrain-error:0.056578\n",
      "[285]\teval-error:0.083483\ttrain-error:0.05568\n",
      "[286]\teval-error:0.083483\ttrain-error:0.05568\n",
      "[287]\teval-error:0.083483\ttrain-error:0.05568\n",
      "[288]\teval-error:0.083483\ttrain-error:0.05568\n",
      "[289]\teval-error:0.084381\ttrain-error:0.057027\n",
      "[290]\teval-error:0.084381\ttrain-error:0.057027\n",
      "[291]\teval-error:0.084381\ttrain-error:0.057027\n",
      "[292]\teval-error:0.084381\ttrain-error:0.057027\n",
      "[293]\teval-error:0.084381\ttrain-error:0.057027\n",
      "[294]\teval-error:0.084381\ttrain-error:0.057027\n",
      "[295]\teval-error:0.084381\ttrain-error:0.057027\n",
      "[296]\teval-error:0.084381\ttrain-error:0.057027\n",
      "[297]\teval-error:0.084381\ttrain-error:0.057027\n",
      "[298]\teval-error:0.083034\ttrain-error:0.056129\n",
      "[299]\teval-error:0.083034\ttrain-error:0.056129\n",
      "[300]\teval-error:0.083034\ttrain-error:0.056129\n",
      "[301]\teval-error:0.083034\ttrain-error:0.056129\n",
      "[302]\teval-error:0.083034\ttrain-error:0.056129\n",
      "[303]\teval-error:0.082585\ttrain-error:0.054333\n",
      "[304]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[305]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[306]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[307]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[308]\teval-error:0.080341\ttrain-error:0.054333\n",
      "[309]\teval-error:0.080341\ttrain-error:0.054333\n",
      "[310]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[311]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[312]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[313]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[314]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[315]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[316]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[317]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[318]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[319]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[320]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[321]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[322]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[323]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[324]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[325]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[326]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[327]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[328]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[329]\teval-error:0.08079\ttrain-error:0.053884\n",
      "[330]\teval-error:0.080341\ttrain-error:0.052088\n",
      "[331]\teval-error:0.080341\ttrain-error:0.052088\n",
      "[332]\teval-error:0.080341\ttrain-error:0.052088\n",
      "[333]\teval-error:0.080341\ttrain-error:0.052088\n",
      "[334]\teval-error:0.080341\ttrain-error:0.052088\n",
      "[335]\teval-error:0.080341\ttrain-error:0.052088\n",
      "[336]\teval-error:0.080341\ttrain-error:0.052088\n",
      "[337]\teval-error:0.078995\ttrain-error:0.05119\n",
      "[338]\teval-error:0.078995\ttrain-error:0.05119\n",
      "[339]\teval-error:0.079892\ttrain-error:0.050292\n",
      "[340]\teval-error:0.078097\ttrain-error:0.049843\n",
      "[341]\teval-error:0.079443\ttrain-error:0.050741\n",
      "[342]\teval-error:0.079443\ttrain-error:0.050741\n",
      "[343]\teval-error:0.078097\ttrain-error:0.049843\n",
      "[344]\teval-error:0.078546\ttrain-error:0.049394\n",
      "[345]\teval-error:0.078546\ttrain-error:0.049394\n",
      "[346]\teval-error:0.078546\ttrain-error:0.049394\n",
      "[347]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[348]\teval-error:0.077199\ttrain-error:0.048496\n",
      "[349]\teval-error:0.077199\ttrain-error:0.048496\n",
      "[350]\teval-error:0.077199\ttrain-error:0.048496\n",
      "[351]\teval-error:0.077199\ttrain-error:0.048496\n",
      "[352]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[353]\teval-error:0.076302\ttrain-error:0.047149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[354]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[355]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[356]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[357]\teval-error:0.074955\ttrain-error:0.046251\n",
      "[358]\teval-error:0.074955\ttrain-error:0.046251\n",
      "[359]\teval-error:0.074955\ttrain-error:0.046251\n",
      "[360]\teval-error:0.074955\ttrain-error:0.046251\n",
      "[361]\teval-error:0.078097\ttrain-error:0.047598\n",
      "[362]\teval-error:0.07675\ttrain-error:0.0467\n",
      "[363]\teval-error:0.07675\ttrain-error:0.0467\n",
      "[364]\teval-error:0.07675\ttrain-error:0.0467\n",
      "[365]\teval-error:0.07675\ttrain-error:0.0467\n",
      "[366]\teval-error:0.078097\ttrain-error:0.047598\n",
      "[367]\teval-error:0.078097\ttrain-error:0.047598\n",
      "[368]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[369]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[370]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[371]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[372]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[373]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[374]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[375]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[376]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[377]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[378]\teval-error:0.076302\ttrain-error:0.047149\n",
      "[379]\teval-error:0.074506\ttrain-error:0.0467\n",
      "[380]\teval-error:0.074506\ttrain-error:0.0467\n",
      "[381]\teval-error:0.074506\ttrain-error:0.0467\n",
      "[382]\teval-error:0.074506\ttrain-error:0.0467\n",
      "[383]\teval-error:0.074506\ttrain-error:0.0467\n",
      "[384]\teval-error:0.074506\ttrain-error:0.0467\n",
      "[385]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[386]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[387]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[388]\teval-error:0.074955\ttrain-error:0.046251\n",
      "[389]\teval-error:0.074955\ttrain-error:0.046251\n",
      "[390]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[391]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[392]\teval-error:0.074955\ttrain-error:0.046251\n",
      "[393]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[394]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[395]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[396]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[397]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[398]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[399]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[400]\teval-error:0.071813\ttrain-error:0.044903\n",
      "[401]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[402]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[403]\teval-error:0.071813\ttrain-error:0.044903\n",
      "[404]\teval-error:0.07316\ttrain-error:0.045802\n",
      "[405]\teval-error:0.071813\ttrain-error:0.044903\n",
      "[406]\teval-error:0.071364\ttrain-error:0.043107\n",
      "[407]\teval-error:0.071364\ttrain-error:0.043107\n",
      "[408]\teval-error:0.071364\ttrain-error:0.043107\n",
      "[409]\teval-error:0.071364\ttrain-error:0.043107\n",
      "[410]\teval-error:0.071364\ttrain-error:0.043107\n",
      "[411]\teval-error:0.071364\ttrain-error:0.043107\n",
      "[412]\teval-error:0.071364\ttrain-error:0.043107\n",
      "[413]\teval-error:0.070018\ttrain-error:0.042209\n",
      "[414]\teval-error:0.070018\ttrain-error:0.042209\n",
      "[415]\teval-error:0.070018\ttrain-error:0.042209\n",
      "[416]\teval-error:0.070018\ttrain-error:0.042209\n",
      "[417]\teval-error:0.070018\ttrain-error:0.042209\n",
      "[418]\teval-error:0.070018\ttrain-error:0.042209\n",
      "[419]\teval-error:0.070018\ttrain-error:0.042209\n",
      "[420]\teval-error:0.070018\ttrain-error:0.042209\n",
      "[421]\teval-error:0.070018\ttrain-error:0.042209\n",
      "[422]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[423]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[424]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[425]\teval-error:0.066876\ttrain-error:0.040862\n",
      "[426]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[427]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[428]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[429]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[430]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[431]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[432]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[433]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[434]\teval-error:0.070467\ttrain-error:0.04176\n",
      "[435]\teval-error:0.068671\ttrain-error:0.041311\n",
      "[436]\teval-error:0.068671\ttrain-error:0.041311\n",
      "[437]\teval-error:0.068671\ttrain-error:0.041311\n",
      "[438]\teval-error:0.068671\ttrain-error:0.041311\n",
      "[439]\teval-error:0.067325\ttrain-error:0.040413\n",
      "[440]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[441]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[442]\teval-error:0.067325\ttrain-error:0.040413\n",
      "[443]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[444]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[445]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[446]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[447]\teval-error:0.067325\ttrain-error:0.040413\n",
      "[448]\teval-error:0.067325\ttrain-error:0.040413\n",
      "[449]\teval-error:0.064183\ttrain-error:0.039066\n",
      "[450]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[451]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[452]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[453]\teval-error:0.06553\ttrain-error:0.039964\n",
      "[454]\teval-error:0.067325\ttrain-error:0.040413\n",
      "[455]\teval-error:0.067325\ttrain-error:0.040413\n",
      "[456]\teval-error:0.067325\ttrain-error:0.040413\n",
      "[457]\teval-error:0.067325\ttrain-error:0.040413\n",
      "[458]\teval-error:0.064183\ttrain-error:0.039066\n",
      "[459]\teval-error:0.064183\ttrain-error:0.039066\n",
      "[460]\teval-error:0.064183\ttrain-error:0.039066\n",
      "[461]\teval-error:0.064183\ttrain-error:0.039066\n",
      "[462]\teval-error:0.064183\ttrain-error:0.039066\n",
      "[463]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[464]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[465]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[466]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[467]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[468]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[469]\teval-error:0.061041\ttrain-error:0.037719\n",
      "[470]\teval-error:0.061041\ttrain-error:0.037719\n",
      "[471]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[472]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[473]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[474]\teval-error:0.062837\ttrain-error:0.038168\n",
      "[475]\teval-error:0.06149\ttrain-error:0.03727\n",
      "[476]\teval-error:0.06149\ttrain-error:0.03727\n",
      "[477]\teval-error:0.06149\ttrain-error:0.03727\n",
      "[478]\teval-error:0.06149\ttrain-error:0.03727\n",
      "[479]\teval-error:0.06149\ttrain-error:0.03727\n",
      "[480]\teval-error:0.06149\ttrain-error:0.03727\n",
      "[481]\teval-error:0.060144\ttrain-error:0.036372\n",
      "[482]\teval-error:0.060144\ttrain-error:0.036372\n",
      "[483]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[484]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[485]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[486]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[487]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[488]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[489]\teval-error:0.060144\ttrain-error:0.036372\n",
      "[490]\teval-error:0.060144\ttrain-error:0.036372\n",
      "[491]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[492]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[493]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[494]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[495]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[496]\teval-error:0.058348\ttrain-error:0.035923\n",
      "[497]\teval-error:0.056553\ttrain-error:0.035474\n",
      "[498]\teval-error:0.056553\ttrain-error:0.035474\n",
      "[499]\teval-error:0.056553\ttrain-error:0.035474\n",
      "XGBoost：94.345%\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "data_train = xgb.DMatrix(x_train, label=y_train)\n",
    "data_test = xgb.DMatrix(x_test, label=y_test)\n",
    "watch_list = [(data_test, 'eval'), (data_train, 'train')]\n",
    "param = {'max_depth': 3, 'eta': 0.1, 'silent': 1, 'objective': 'binary:logistic'}  # 将需要设置的参数设置一下\n",
    "        # 'subsample': 1, 'alpha': 0, 'lambda': 0, 'min_child_weight': 1}\n",
    "\n",
    "# 学习数据（打印出每次迭代之后的训练集合测试集上的误差）\n",
    "bst = xgb.train(param, data_train, num_boost_round=500, evals=watch_list)  # 这里做500次迭代 \n",
    "# 预测数据\n",
    "y_hat = bst.predict(data_test)\n",
    "# write_result(bst, 3)\n",
    "y_hat[y_hat > 0.5] = 1\n",
    "y_hat[~(y_hat > 0.5)] = 0\n",
    "# 模型得分\n",
    "xgb_rate = show_accuracy(y_hat, y_test, 'XGBoost ')\n",
    "print ('XGBoost：%.3f%%' % xgb_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较3种方法的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic回归：79.129%\n",
      "随机森林：97.397%\n",
      "XGBoost：94.345%\n"
     ]
    }
   ],
   "source": [
    "print ('Logistic回归：%.3f%%' % lr_rate)\n",
    "print ('随机森林：%.3f%%' % rfc_rate)\n",
    "print ('XGBoost：%.3f%%' % xgb_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：可见，随机森林（20颗树）和XGBoost（500次迭代）的分类准确率还是要优于Logistic回归的"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
